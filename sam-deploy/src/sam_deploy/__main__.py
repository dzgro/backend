"""
SAM Deploy - Main Entry Point

Provides interactive deployment selection with 4 options:
1. Core Product Features (All Regions) - Full deployment to all 4 regions
2. AMS Features (All Regions) - AMS-only deployment to all 4 regions
3. Deploy to Staging (Requires OTP) - Promotes Lambda aliases from DEV to STAGING
4. Deploy to Production (Requires OTP) - Promotes Lambda aliases from STAGING to PROD
"""

import sys
import time
import random
from typing import Tuple, Optional, List
from pathlib import Path

import boto3
import inquirer
from botocore.exceptions import ClientError

from sam_deploy.config.mapping import ENVIRONMENT, Region, LAMBDAS, LambdaName
from sam_deploy.builder.template_builder import TemplateBuilder
from sam_deploy.builder.build_layers import LambdaLayerBuilder
from sam_deploy.builder.build_lambdas import LambdaBuilder
from sam_deploy.builder.build_http_apis import HttpApiBuilder
from sam_deploy.builder.build_queues import QueueBuilder
from sam_deploy.builder.build_buckets import BucketBuilder
from sam_deploy.builder.build_cognito import CognitoBuilder
from sam_deploy.executor.sam_executor import SAMExecutor
from sam_deploy.utils import docker_manager


def select_deployment_type() -> Tuple[str, Optional[List[Region]]]:
    """
    Interactive deployment type selection.

    Returns:
        Tuple of (deployment_type, regions):
        - deployment_type: 'core', 'ams', 'promote_staging', 'promote_prod'
        - regions: List of Region enum values or None for promotions
    """
    print("\n" + "=" * 80)
    print("SAM DEPLOY - Interactive Deployment Selection")
    print("=" * 80)

    # TESTING MODE: Auto-select Core Product Features
    print("\n[TESTING MODE] Auto-selecting: Core Product Features")
    selection = "1. Core Product Features (All Regions)"

    if "Core Product" in selection:
        print("\n[OK] Selected: Core Product Features")
        print("   Deploying: All APIs, Lambdas, Queues, Buckets, Cognito, Certificates")
        print("   Regions: ap-south-1 (TESTING - single region only)")
        print("   Auto-publishes to DEV alias")
        # TESTING: Only deploy to ap-south-1
        return "core", [Region.DEFAULT]

    elif "AMS Features" in selection:
        print("\n[OK] Selected: AMS Features")
        print("   Deploying: AMS Lambdas and Queues only")
        print("   Regions: ap-south-1, eu-west-1, us-east-1, us-west-2 (sequential)")
        return "ams", Region.all()

    elif "Staging" in selection:
        print("\n[OK] Selected: Deploy to Staging")
        print("   Promotes Lambda versions from DEV to STAGING alias")
        print("   Applies to: All regions")
        print("   Secure operation with email OTP verification")
        return "promote_staging", None

    elif "Production" in selection:
        print("\n[OK] Selected: Deploy to Production")
        print("   Promotes Lambda versions from STAGING to PROD alias")
        print("   Applies to: All regions")
        print("   Secure operation with email OTP verification")
        return "promote_prod", None

    else:
        print("[ERROR] Invalid selection. Exiting.")
        sys.exit(1)


def generate_random_otp() -> str:
    """Generate 6-digit random OTP"""
    return str(random.randint(100000, 999999))


def send_otp_via_ses(otp: str, recipient: str, stage: str) -> None:
    """
    Send OTP via AWS SES with stage information.

    Args:
        otp: 6-digit OTP code
        recipient: Email address to send OTP to
        stage: Target stage (staging or production)

    Raises:
        Exception: If email sending fails
    """
    ses = boto3.client('ses', region_name='ap-south-1')

    subject = f"[SECURE] SAM Deploy: Lambda Promotion OTP - {stage.upper()}"
    body = f"""
Lambda Alias Promotion OTP

Target Stage: {stage.upper()}

Your One-Time Password (OTP) for Lambda alias promotion:

{otp}

This OTP is valid for this session only.
Do not share this code with anyone.

If you did not initiate this deployment, please contact your administrator immediately.

---
Dzgro Technologies
Generated by SAM Deploy System
"""

    try:
        ses.send_email(
            Source='noreply@dzgro.com',  # Must be verified in SES
            Destination={'ToAddresses': [recipient]},
            Message={
                'Subject': {'Data': subject},
                'Body': {'Text': {'Data': body}}
            }
        )
        print(f"[EMAIL] Email sent successfully to {recipient} for {stage.upper()} promotion")
    except Exception as e:
        print(f"[ERROR] Failed to send email: {e}")
        raise


def get_all_lambda_functions() -> List[str]:
    """
    Get all Lambda function names from configuration.

    Returns:
        List of Lambda function names (without environment suffix)
    """
    lambda_names = []
    for lambda_config in LAMBDAS:
        # Use a temporary builder to get function names
        temp_builder = TemplateBuilder()
        fn_name = temp_builder.getFunctionName(lambda_config.name)
        lambda_names.append(fn_name)

    return lambda_names


def promote_to_staging_with_otp() -> None:
    """
    Promote Lambda versions from DEV to STAGING with OTP verification.

    This function:
    1. Shows current DEV versions for all Lambdas
    2. Requests confirmation
    3. Sends OTP via SES to dzgrotechnologies@gmail.com
    4. Verifies OTP (3 attempts allowed)
    5. Updates all Lambda STAGING aliases to point to DEV versions

    Applies to ALL 4 regions sequentially.
    """
    print("\n[CRITICAL] CRITICAL OPERATION: Promote to STAGING")
    print("=" * 80)

    all_lambdas = get_all_lambda_functions()
    all_regions = Region.all()

    print(f"\nThis will promote Lambda aliases across {len(all_regions)} regions:")
    for region in all_regions:
        print(f"  - {region.value}")

    # Show current state for first region (ap-south-1)
    print(f"\nLambdas to be promoted (DEV → STAGING) in {all_regions[0].value}:")
    lambda_client = boto3.client('lambda', region_name=all_regions[0].value)

    version_map = {}
    for lambda_name in all_lambdas:
        try:
            dev_alias = lambda_client.get_alias(
                FunctionName=lambda_name,
                Name='dev'
            )
            version = dev_alias['FunctionVersion']
            version_map[lambda_name] = version
            print(f"  - {lambda_name}: Version {version}")
        except ClientError as e:
            if 'ResourceNotFoundException' in str(e):
                print(f"  - {lambda_name}: [WARNING] DEV alias not found (may not exist in this region)")
            else:
                print(f"  - {lambda_name}: [WARNING] Could not get DEV version: {e}")

    # Confirmation
    confirm = input("\n[WARNING] Proceed with promotion to STAGING across all regions? (yes/no): ")
    if confirm.lower() != "yes":
        print("[ERROR] Promotion cancelled")
        return

    # Generate and send OTP
    otp = generate_random_otp()
    send_otp_via_ses(otp, "dzgrotechnologies@gmail.com", "staging")
    print(f"\n[EMAIL] OTP sent to dzgrotechnologies@gmail.com")
    print("Please check your email for the OTP code.")

    # Verify OTP (3 attempts)
    for attempt in range(3):
        user_otp = input(f"\nEnter OTP (Attempt {attempt + 1}/3): ")
        if user_otp == otp:
            break
        else:
            if attempt < 2:
                print(f"[ERROR] Invalid OTP. {2 - attempt} attempts remaining.")
            else:
                print("[ERROR] Invalid OTP. Maximum attempts exceeded. Promotion aborted.")
                return

    # Update Lambda aliases across all regions
    print("\n[DEPLOY] Updating Lambda aliases to STAGING across all regions...")
    total_success = 0
    total_attempts = 0

    for region in all_regions:
        print(f"\n[REGION] Region: {region.value}")
        lambda_client = boto3.client('lambda', region_name=region.value)

        for lambda_name in all_lambdas:
            total_attempts += 1
            try:
                # Get DEV version for this region
                dev_alias = lambda_client.get_alias(
                    FunctionName=lambda_name,
                    Name='dev'
                )
                version = dev_alias['FunctionVersion']

                # Update STAGING alias
                lambda_client.update_alias(
                    FunctionName=lambda_name,
                    Name='staging',
                    FunctionVersion=version
                )
                print(f"  [OK] {lambda_name}: staging -> Version {version}")
                total_success += 1
            except ClientError as e:
                if 'ResourceNotFoundException' in str(e):
                    print(f"  [WARNING] {lambda_name}: Not found in this region (skipped)")
                else:
                    print(f"  [ERROR] {lambda_name}: Failed - {e}")

    print(f"\n{'=' * 80}")
    print(f"[OK] Promoted {total_success}/{total_attempts} lambdas to STAGING successfully!")
    print(f"{'=' * 80}")


def promote_to_production_with_otp() -> None:
    """
    Promote Lambda versions from STAGING to PROD with OTP verification.

    This function:
    1. Shows current STAGING versions for all Lambdas
    2. Requests confirmation
    3. Sends OTP via SES to dzgrotechnologies@gmail.com
    4. Verifies OTP (3 attempts allowed)
    5. Updates all Lambda PROD aliases to point to STAGING versions

    Applies to ALL 4 regions sequentially.
    """
    print("\n[CRITICAL][CRITICAL] CRITICAL OPERATION: Promote to PRODUCTION [CRITICAL][CRITICAL]")
    print("=" * 80)

    all_lambdas = get_all_lambda_functions()
    all_regions = Region.all()

    print(f"\nThis will promote Lambda aliases across {len(all_regions)} regions:")
    for region in all_regions:
        print(f"  - {region.value}")

    # Show current state for first region (ap-south-1)
    print(f"\nLambdas to be promoted (STAGING → PRODUCTION) in {all_regions[0].value}:")
    lambda_client = boto3.client('lambda', region_name=all_regions[0].value)

    version_map = {}
    for lambda_name in all_lambdas:
        try:
            staging_alias = lambda_client.get_alias(
                FunctionName=lambda_name,
                Name='staging'
            )
            version = staging_alias['FunctionVersion']
            version_map[lambda_name] = version
            print(f"  - {lambda_name}: Version {version}")
        except ClientError as e:
            if 'ResourceNotFoundException' in str(e):
                print(f"  - {lambda_name}: [WARNING] STAGING alias not found (may not exist in this region)")
            else:
                print(f"  - {lambda_name}: [WARNING] Could not get STAGING version: {e}")

    # Confirmation
    confirm = input("\n[WARNING][WARNING] Proceed with promotion to PRODUCTION across all regions? (yes/no): ")
    if confirm.lower() != "yes":
        print("[ERROR] Promotion cancelled")
        return

    # Generate and send OTP
    otp = generate_random_otp()
    send_otp_via_ses(otp, "dzgrotechnologies@gmail.com", "production")
    print(f"\n[EMAIL] OTP sent to dzgrotechnologies@gmail.com")
    print("Please check your email for the OTP code.")

    # Verify OTP (3 attempts)
    for attempt in range(3):
        user_otp = input(f"\nEnter OTP (Attempt {attempt + 1}/3): ")
        if user_otp == otp:
            break
        else:
            if attempt < 2:
                print(f"[ERROR] Invalid OTP. {2 - attempt} attempts remaining.")
            else:
                print("[ERROR] Invalid OTP. Maximum attempts exceeded. Promotion aborted.")
                return

    # Update Lambda aliases across all regions
    print("\n[DEPLOY] Updating Lambda aliases to PRODUCTION across all regions...")
    total_success = 0
    total_attempts = 0

    for region in all_regions:
        print(f"\n[REGION] Region: {region.value}")
        lambda_client = boto3.client('lambda', region_name=region.value)

        for lambda_name in all_lambdas:
            total_attempts += 1
            try:
                # Get STAGING version for this region
                staging_alias = lambda_client.get_alias(
                    FunctionName=lambda_name,
                    Name='staging'
                )
                version = staging_alias['FunctionVersion']

                # Update PROD alias
                lambda_client.update_alias(
                    FunctionName=lambda_name,
                    Name='prod',
                    FunctionVersion=version
                )
                print(f"  [OK] {lambda_name}: prod -> Version {version}")
                total_success += 1
            except ClientError as e:
                if 'ResourceNotFoundException' in str(e):
                    print(f"  [WARNING] {lambda_name}: Not found in this region (skipped)")
                else:
                    print(f"  [ERROR] {lambda_name}: Failed - {e}")

    print(f"\n{'=' * 80}")
    print(f"[OK] Promoted {total_success}/{total_attempts} lambdas to PRODUCTION successfully!")
    print(f"{'=' * 80}")


def deploy_core_product_features(regions: List[Region]) -> None:
    """
    Deploy ALL core product features to ALL 4 regions in a SINGLE STACK per region.

    Single stack contains:
    - Lambda layers (built once, reused for all regions)
    - Certificates (Auth us-east-1, API/Webhook region-specific) - 1 set for all envs
    - Cognito User Pools - 3 pools (dev, staging, prod)
    - Lambda functions - 1 function (will create 3 aliases later: dev, staging, prod)
    - HTTP APIs - 1 API with 3 stages (dev, staging, prod)
    - SQS queues - 3 queues per type (dev, staging, prod)
    - S3 buckets - 3 buckets per type (dev, staging, prod)

    Args:
        regions: List of regions to deploy to (all 4 regions)
    """
    print("\n" + "=" * 80)
    print("[MULTI-REGION] CORE PRODUCT FEATURES - Multi-Region Deployment (Single Stack)")
    print("=" * 80)
    print(f"\nDeploying to {len(regions)} regions:")
    for idx, region in enumerate(regions, 1):
        print(f"  {idx}. {region.value}")
    print(f"\nEach stack contains resources for ALL 3 environments (dev, staging, prod)")

    # Environments - all will be in the same stack
    environments = [ENVIRONMENT.DEV, ENVIRONMENT.STAGING, ENVIRONMENT.PROD]

    # Build layers ONCE (will be reused across all regions)
    layer_arns_cache = {}

    for region_idx, region in enumerate(regions, 1):
        print(f"\n{'=' * 80}")
        print(f"REGION {region_idx}/{len(regions)}: {region.value}")
        print(f"{'=' * 80}")

        # Create ONE builder for this region (will contain all environments)
        # Use DEV as the base environment, but we'll create resources for all 3
        builder = TemplateBuilder(ENVIRONMENT.DEV)

            # Step 1: Build Lambda layers (only on first region + first env)
            if region_idx == 1 and env_idx == 1:
                print(f"\n[1/8] [PACKAGE] Building Lambda layers (will be cached for other regions and environments)...")
                layer_builder = LambdaLayerBuilder(env, region)
                layer_arns_cache[region.value] = layer_builder.execute_optimized()
                print(f"  [OK] Layers built: {len(layer_arns_cache[region.value])} layers")
            elif region_idx == 1:
                print(f"\n[1/8] [PACKAGE] Using cached Lambda layers from {ENVIRONMENT.DEV.value}...")
                # Reuse layers from DEV for staging/prod in same region
                print(f"  [OK] Layers reused: {len(layer_arns_cache[region.value])} layers")
            else:
                print(f"\n[1/8] [PACKAGE] Publishing Lambda layers to {region.value}...")
                if region.value not in layer_arns_cache:
                    layer_builder = LambdaLayerBuilder(env, region)
                    layer_arns_cache[region.value] = layer_builder.execute_optimized()
                print(f"  [OK] Layers published to {region.value}: {len(layer_arns_cache[region.value])} layers")

            # Get layers for current region
            current_layer_arns = layer_arns_cache[region.value]

            # Step 2: Build certificates (Auth, API, Webhook)
            print(f"\n[2/8] [SECURE] Building certificates for {env.value.upper()} (Auth, API, Webhook)...")
            try:
                # Auth certificate (us-east-1 for Cognito)
                auth_certificate_arn = builder.getWildCardCertificateArn('Auth')
                # API certificate (region-specific)
                api_certificate_arn = builder.getWildCardCertificateArn('Api')
                # Webhook certificate (region-specific)
                webhook_certificate_arn = builder.getWildCardCertificateArn('Webhook')
                print(f"  [OK] Certificates ready for {env.value.upper()}")
            except Exception as e:
                print(f"  [ERROR] Certificate setup failed: {e}")
                raise

            # Step 3: Build Cognito User Pool (separate per environment)
            print(f"\n[3/8] [USER] Building Cognito User Pool for {env.value.upper()}...")
            try:
                cognito_builder = CognitoBuilder(builder)
                cognito_builder.execute(auth_certificate_arn)
                print(f"  [OK] Cognito User Pool created for {env.value.upper()}")
            except Exception as e:
                print(f"  [ERROR] Cognito build failed: {e}")
                raise

            # Step 4: Build Lambda functions
            print(f"\n[4/8] [LAMBDA] Building Lambda functions for {env.value.upper()}...")
            try:
                lambda_builder = LambdaBuilder(builder)
                lambda_builder.execute(region, current_layer_arns)
                print(f"  [OK] Lambda functions created for {env.value.upper()}")
            except Exception as e:
                print(f"  [ERROR] Lambda build failed: {e}")
                raise

            # Step 5: Build HTTP APIs (API + Webhook)
            print(f"\n[5/8] [API] Building HTTP APIs for {env.value.upper()} (API + Webhook)...")
            try:
                api_builder = HttpApiBuilder(builder)
                api_builder.execute(api_certificate_arn, webhook_certificate_arn, region)
                print(f"  [OK] HTTP APIs created for {env.value.upper()}")
            except Exception as e:
                print(f"  [ERROR] HTTP API build failed: {e}")
                raise

            # Step 6: Build SQS queues
            print(f"\n[6/8] [QUEUE] Building SQS queues for {env.value.upper()}...")
            try:
                queue_builder = QueueBuilder(builder)
                # Iterate through all lambdas and build their queues
                for lambda_config in LAMBDAS:
                    # Check if this lambda is configured for this region and environment
                    if env not in lambda_config.env:
                        continue
                    lambda_region = next((lr for lr in lambda_config.regions if lr.region == region), None)
                    if lambda_region and lambda_region.queue:
                        queue_builder.execute(lambda_config.name, lambda_region.queue, region)
                print(f"  [OK] SQS queues created for {env.value.upper()}")
            except Exception as e:
                print(f"  [ERROR] Queue build failed: {e}")
                raise

            # Step 7: Build S3 buckets
            print(f"\n[7/8] [STORAGE] Building S3 buckets for {env.value.upper()}...")
            try:
                bucket_builder = BucketBuilder(builder)
                # Iterate through all lambdas and build their S3 buckets
                for lambda_config in LAMBDAS:
                    # Check if this lambda is configured for this region and environment
                    if env not in lambda_config.env:
                        continue
                    lambda_region = next((lr for lr in lambda_config.regions if lr.region == region), None)
                    if lambda_region and lambda_region.s3:
                        bucket_builder.execute(lambda_region.s3, region)
                print(f"  [OK] S3 buckets created for {env.value.upper()}")
            except Exception as e:
                print(f"  [ERROR] Bucket build failed: {e}")
                raise

            # Step 8: Save template and deploy
            print(f"\n[8/8] [SAVE] Saving SAM template for {env.value.upper()} in {region.value}...")
            try:
                executor = SAMExecutor(builder)
                template_path = executor.saveTemplateAsYaml(region)
                print(f"  [OK] Template saved: {template_path}")

                # Auto-deploy without confirmation
                print(f"\n[DEPLOY] Deploying {env.value.upper()} to {region.value}...")
                executor.execute(region)
                print(f"  [OK] Successfully deployed {env.value.upper()} to {region.value}")

            except Exception as e:
                print(f"  [ERROR] Deployment failed for {env.value.upper()}: {e}")
                raise

    print(f"\n{'=' * 80}")
    print(f"[OK] ALL REGIONS AND ENVIRONMENTS DEPLOYED SUCCESSFULLY!")
    print(f"  - {len(regions)} regions × {len(environments)} environments = {len(regions) * len(environments)} stacks deployed")
    print(f"{'=' * 80}")


def deploy_ams_features_multiregion(regions: List[Region]) -> None:
    """
    Deploy ONLY AMS features to ALL 4 regions sequentially.

    This includes:
    - Lambda layers (built once, reused for all regions)
    - AMS Lambda functions (AmsChange, AmsPerformance)
    - AMS SQS queues (AMS_CHANGE, AMS_PERFORMANCE)

    Excludes:
    - HTTP APIs
    - S3 Buckets
    - Cognito
    - Certificates (except for ap-south-1 if needed)
    - Core Product Lambdas

    Args:
        regions: List of regions to deploy to (all 4 regions)
    """
    print("\n" + "=" * 80)
    print("[AMS] AMS FEATURES - Multi-Region Deployment")
    print("=" * 80)
    print(f"\nDeploying to {len(regions)} regions sequentially:")
    for idx, region in enumerate(regions, 1):
        print(f"  {idx}. {region.value}")

    # Build layers ONCE (will be reused across all regions)
    layer_arns_cache = None

    for region_idx, region in enumerate(regions, 1):
        print(f"\n{'=' * 80}")
        print(f"REGION {region_idx}/{len(regions)}: {region.value}")
        print(f"{'=' * 80}")

        builder = TemplateBuilder()

        # Step 1: Build Lambda layers (only on first region)
        if region_idx == 1:
            print(f"\n[1/4] [PACKAGE] Building Lambda layers (will be cached for other regions)...")
            layer_builder = LambdaLayerBuilder(builder.env, region)
            layer_arns_cache = layer_builder.execute_optimized()
            print(f"  [OK] Layers built: {len(layer_arns_cache)} layers")
        else:
            print(f"\n[1/4] [PACKAGE] Using cached Lambda layers from first region...")
            layer_builder = LambdaLayerBuilder(builder.env, region)
            layer_arns_cache = layer_builder.execute_optimized()
            print(f"  [OK] Layers published to {region.value}: {len(layer_arns_cache)} layers")

        # Step 2: Build ONLY AMS Lambda functions
        print(f"\n[2/4] [LAMBDA] Building AMS Lambda functions (AmsChange, AmsPerformance)...")
        try:
            lambda_builder = LambdaBuilder(builder)
            # Filter to only AMS lambdas
            for lambda_config in LAMBDAS:
                if lambda_config.name in [LambdaName.AmsChange, LambdaName.AmsPerformance]:
                    # Check if this lambda is configured for this region
                    if any(lr.region == region for lr in lambda_config.regions):
                        lambda_builder.build_lambda_with_aliases(lambda_config, layer_arns_cache, region)
            print(f"  [OK] AMS Lambda functions created")
        except Exception as e:
            print(f"  [ERROR] Lambda build failed: {e}")
            raise

        # Step 3: Build ONLY AMS SQS queues
        print(f"\n[3/4] [QUEUE] Building AMS SQS queues...")
        try:
            queue_builder = QueueBuilder(builder)
            # Build only AMS queues
            for lambda_config in LAMBDAS:
                if lambda_config.name in [LambdaName.AmsChange, LambdaName.AmsPerformance]:
                    lambda_region = next((lr for lr in lambda_config.regions if lr.region == region), None)
                    if lambda_region and lambda_region.queue:
                        queue_builder.execute(lambda_config.name, lambda_region.queue, region)
            print(f"  [OK] AMS SQS queues created")
        except Exception as e:
            print(f"  [ERROR] Queue build failed: {e}")
            raise

        # Step 4: Save template and deploy
        print(f"\n[4/4] [DEPLOY] Deploying SAM template to {region.value}...")
        try:
            executor = SAMExecutor(builder)
            executor.saveTemplateAsYaml(region)
            executor.execute(region)
            print(f"  [OK] Successfully deployed to {region.value}")
        except Exception as e:
            print(f"  [ERROR] Deployment failed: {e}")
            raise

    print(f"\n{'=' * 80}")
    print(f"[OK] ALL AMS REGIONS DEPLOYED SUCCESSFULLY!")
    print(f"{'=' * 80}")


def create_local_resources() -> None:
    """
    Create LOCAL environment resources (S3 buckets and SQS queues only).

    These resources are created locally and NOT deployed to AWS.
    - S3 buckets for all bucket types (LOCAL environment)
    - SQS queues for all queue types (LOCAL environment)
    - NO Lambda functions
    - NO EventSourceMapping (queues are not triggered by Lambda)
    """
    print("\n" + "=" * 80)
    print("[LOCAL] Creating LOCAL environment resources")
    print("=" * 80)

    builder = TemplateBuilder()

    # Create S3 buckets locally
    print("\n[1/2] [STORAGE] Creating LOCAL S3 buckets...")
    try:
        from dzgroshared.storage.model import S3Bucket
        import boto3

        s3 = boto3.client('s3', endpoint_url='http://localhost:4566')  # LocalStack

        for bucket in S3Bucket.all():
            bucket_name = builder.getBucketName(bucket)
            try:
                s3.create_bucket(Bucket=bucket_name)
                print(f"  [OK] Created: {bucket_name}")
            except Exception as e:
                if 'BucketAlreadyExists' in str(e) or 'BucketAlreadyOwnedByYou' in str(e):
                    print(f"  [INFO] Already exists: {bucket_name}")
                else:
                    print(f"  [ERROR] Failed to create {bucket_name}: {e}")
    except Exception as e:
        print(f"  [ERROR] S3 bucket creation failed: {e}")
        raise

    # Create SQS queues locally
    print("\n[2/2] [QUEUE] Creating LOCAL SQS queues...")
    try:
        from dzgroshared.sqs.model import QueueName
        import boto3

        sqs = boto3.client('sqs', endpoint_url='http://localhost:4566')  # LocalStack

        for queue_name_enum in QueueName.all():
            # Main queue
            queue_name = builder.getQueueName(queue_name_enum, 'Q')
            try:
                sqs.create_queue(QueueName=queue_name)
                print(f"  [OK] Created: {queue_name}")
            except Exception as e:
                if 'QueueAlreadyExists' in str(e):
                    print(f"  [INFO] Already exists: {queue_name}")
                else:
                    print(f"  [ERROR] Failed to create {queue_name}: {e}")

            # Dead letter queue
            dlq_name = builder.getQueueName(queue_name_enum, 'DLQ')
            try:
                sqs.create_queue(QueueName=dlq_name)
                print(f"  [OK] Created: {dlq_name}")
            except Exception as e:
                if 'QueueAlreadyExists' in str(e):
                    print(f"  [INFO] Already exists: {dlq_name}")
                else:
                    print(f"  [ERROR] Failed to create {dlq_name}: {e}")
    except Exception as e:
        print(f"  [ERROR] SQS queue creation failed: {e}")
        raise

    print(f"\n{'=' * 80}")
    print(f"[OK] LOCAL resources created successfully!")
    print(f"{'=' * 80}")


def main():
    """
    Main entry point for SAM Deploy.

    Flow:
    1. Start Docker (required for SAM builds)
    2. Detect environment (LOCAL vs DEV/STAGING/PROD)
    3. If LOCAL: Create S3 buckets and SQS queues locally
    4. If not LOCAL: Interactive deployment selection
       - Core Product Features (All Regions)
       - AMS Features (All Regions)
       - Deploy to Staging (OTP required)
       - Deploy to Production (OTP required)
    5. Stop Docker after completion
    """
    print("\n" + "=" * 80)
    print("SAM DEPLOY - AWS Serverless Application Model Deployment Tool")
    print("=" * 80)

    try:
        # Start Docker
        print("\n[DOCKER] Starting Docker...")
        docker_manager.start_ubuntu_docker()

        # Create a temporary builder to detect environment
        temp_builder = TemplateBuilder()

        if temp_builder.env == ENVIRONMENT.LOCAL:
            print(f"\n[OK] Environment: LOCAL")
            print("   Creating S3 buckets and SQS queues locally...")
            create_local_resources()
        else:
            print(f"\n[OK] Environment: {temp_builder.env.value.upper()}")

            # Interactive deployment selection
            deployment_type, regions = select_deployment_type()

            if deployment_type == "core" and regions:
                deploy_core_product_features(regions)
            elif deployment_type == "ams" and regions:
                deploy_ams_features_multiregion(regions)
            elif deployment_type == "promote_staging":
                promote_to_staging_with_otp()
            elif deployment_type == "promote_prod":
                promote_to_production_with_otp()

        print("\n[OK] Deployment completed successfully!")

    except KeyboardInterrupt:
        print("\n\n[WARNING] Deployment interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n[ERROR] Deployment failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        # Stop Docker
        print("\n[DOCKER] Stopping Docker...")
        try:
            docker_manager.stop_ubuntu_docker()
        except Exception as e:
            print(f"[WARNING] Warning: Failed to stop Docker: {e}")


if __name__ == "__main__":
    main()
